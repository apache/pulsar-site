"use strict";(self.webpackChunkwebsite_next=self.webpackChunkwebsite_next||[]).push([[5691],{37388:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>d,default:()=>u,frontMatter:()=>o,metadata:()=>t,toc:()=>h});const t=JSON.parse('{"id":"tiered-storage-filesystem","title":"Use filesystem offloader with Pulsar","description":"This chapter guides you through every step of installing and configuring the filesystem offloader and using it with Pulsar.","source":"@site/docs/tiered-storage-filesystem.md","sourceDirName":".","slug":"/tiered-storage-filesystem","permalink":"/docs/next/tiered-storage-filesystem","draft":false,"unlisted":false,"editUrl":"https://github.com/apache/pulsar-site/edit/main/docs/tiered-storage-filesystem.md","tags":[],"version":"current","frontMatter":{"id":"tiered-storage-filesystem","title":"Use filesystem offloader with Pulsar","sidebar_label":"Filesystem offloader"},"sidebar":"docsSidebar","previous":{"title":"GCS offloader","permalink":"/docs/next/tiered-storage-gcs"},"next":{"title":"Azure BlobStore offloader","permalink":"/docs/next/tiered-storage-azure"}}');var r=s(74848),a=s(28453),l=s(11470),i=s(19365);const o={id:"tiered-storage-filesystem",title:"Use filesystem offloader with Pulsar",sidebar_label:"Filesystem offloader"},d=void 0,c={},h=[{value:"Installation",id:"installation",level:2},{value:"Prerequisite",id:"prerequisite",level:3},{value:"Steps",id:"steps",level:3},{value:"Configuration",id:"configuration",level:2},{value:"Configure filesystem offloader driver",id:"configure-filesystem-offloader-driver",level:3},{value:"Run filesystem offloader automatically",id:"run-filesystem-offloader-automatically",level:3},{value:"Example",id:"example",level:4},{value:"Run filesystem offloader manually",id:"run-filesystem-offloader-manually",level:3},{value:"Example",id:"example-1",level:4},{value:"Tutorial",id:"tutorial",level:2},{value:"Offload data to HDFS",id:"offload-data-to-hdfs",level:3},{value:"Step 1: Prepare the HDFS environment",id:"step-1-prepare-the-hdfs-environment",level:4},{value:"Step 2: Install the filesystem offloader",id:"step-2-install-the-filesystem-offloader",level:4},{value:"Step 3: Configure the filesystem offloader",id:"step-3-configure-the-filesystem-offloader",level:4},{value:"Step 4: Offload data from BookKeeper to filesystem",id:"step-4-offload-data-from-bookkeeper-to-filesystem",level:4},{value:"Offload data to NFS",id:"offload-data-to-nfs",level:3},{value:"Step 1: Install the filesystem offloader",id:"step-1-install-the-filesystem-offloader",level:4},{value:"Step 2: Mount your NFS to your local filesystem",id:"step-2-mount-your-nfs-to-your-local-filesystem",level:4},{value:"Step 3: Configure the filesystem offloader driver",id:"step-3-configure-the-filesystem-offloader-driver",level:4},{value:"Step 4: Offload data from BookKeeper to filesystem",id:"step-4-offload-data-from-bookkeeper-to-filesystem-1",level:4},{value:"Read offloaded data from filesystem",id:"read-offloaded-data-from-filesystem",level:2}];function f(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h2:"h2",h3:"h3",h4:"h4",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.p,{children:"This chapter guides you through every step of installing and configuring the filesystem offloader and using it with Pulsar."}),"\n",(0,r.jsx)(n.h2,{id:"installation",children:"Installation"}),"\n",(0,r.jsx)(n.p,{children:"This section describes how to install the filesystem offloader."}),"\n",(0,r.jsx)(n.h3,{id:"prerequisite",children:"Prerequisite"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Pulsar: 2.4.2 or higher versions"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"steps",children:"Steps"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"/docs/next/getting-started-standalone#download-pulsar-distribution",children:"Download the Pulsar tarball"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Download and untar the Pulsar offloaders package, then copy the Pulsar offloaders as ",(0,r.jsx)(n.code,{children:"offloaders"})," in the Pulsar directory. See ",(0,r.jsx)(n.a,{href:"/docs/next/tiered-storage-overview#how-to-install-tiered-storage-offloaders",children:"Install tiered storage offloaders"}),"."]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"configuration",children:"Configuration"}),"\n",(0,r.jsx)(n.admonition,{type:"note",children:(0,r.jsx)(n.p,{children:"Before offloading data from BookKeeper to filesystem, you need to configure some properties of the filesystem offloader driver."})}),"\n",(0,r.jsx)(n.p,{children:"Besides, you can also configure the filesystem offloader to run it automatically or trigger it manually."}),"\n",(0,r.jsx)(n.h3,{id:"configure-filesystem-offloader-driver",children:"Configure filesystem offloader driver"}),"\n",(0,r.jsxs)(n.p,{children:["You can configure the filesystem offloader driver in the ",(0,r.jsx)(n.code,{children:"broker.conf"})," or ",(0,r.jsx)(n.code,{children:"standalone.conf"})," configuration file."]}),"\n",(0,r.jsxs)(l.A,{defaultValue:"HDFS",values:[{label:"HDFS",value:"HDFS"},{label:"NFS",value:"NFS"}],children:[(0,r.jsx)(i.A,{value:"HDFS",children:(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Required"})," configurations are as below."]}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Parameter"}),(0,r.jsx)(n.th,{children:"Description"}),(0,r.jsx)(n.th,{children:"Example value"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"managedLedgerOffloadDriver"})}),(0,r.jsx)(n.td,{children:"Offloader driver name, which is case-insensitive."}),(0,r.jsx)(n.td,{children:"filesystem"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"fileSystemURI"})}),(0,r.jsx)(n.td,{children:"Connection address, which is the URI to access the default Hadoop distributed file system."}),(0,r.jsx)(n.td,{children:"hdfs://127.0.0.1:9000"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"offloadersDirectory"})}),(0,r.jsx)(n.td,{children:"Offloader directory"}),(0,r.jsx)(n.td,{children:"offloaders"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"fileSystemProfilePath"})}),(0,r.jsx)(n.td,{children:"Hadoop profile path. The configuration file is stored in the Hadoop profile path. It contains various settings for Hadoop performance tuning."}),(0,r.jsx)(n.td,{children:"conf/filesystem_offload_core_site.xml"})]})]})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Optional"})," configurations are as below."]}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Parameter"}),(0,r.jsx)(n.th,{children:"Description"}),(0,r.jsx)(n.th,{children:"Example value"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"managedLedgerMinLedgerRolloverTimeMinutes"})}),(0,r.jsxs)(n.td,{children:["Minimum time between ledger rollover for a topic. ",(0,r.jsx)("br",{}),(0,r.jsx)("br",{}),(0,r.jsx)(n.strong,{children:"Note"}),": it is not recommended to set this parameter in the production environment."]}),(0,r.jsx)(n.td,{children:"10"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"managedLedgerMaxEntriesPerLedger"})}),(0,r.jsxs)(n.td,{children:["Maximum number of entries to append to a ledger before triggering a rollover.",(0,r.jsx)("br",{}),(0,r.jsx)("br",{}),(0,r.jsx)(n.strong,{children:"Note"}),": it is not recommended to set this parameter in the production environment."]}),(0,r.jsx)(n.td,{children:"50000"})]})]})]}),"\n"]}),"\n"]})}),(0,r.jsx)(i.A,{value:"NFS",children:(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Required"})," configurations are as below."]}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Parameter"}),(0,r.jsx)(n.th,{children:"Description"}),(0,r.jsx)(n.th,{children:"Example value"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"managedLedgerOffloadDriver"})}),(0,r.jsx)(n.td,{children:"Offloader driver name, which is case-insensitive."}),(0,r.jsx)(n.td,{children:"filesystem"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"offloadersDirectory"})}),(0,r.jsx)(n.td,{children:"Offloader directory"}),(0,r.jsx)(n.td,{children:"offloaders"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"fileSystemProfilePath"})}),(0,r.jsx)(n.td,{children:"NFS profile path. The configuration file is stored in the NFS profile path. It contains various settings for performance tuning."}),(0,r.jsx)(n.td,{children:"conf/filesystem_offload_core_site.xml"})]})]})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Optional"})," configurations are as below."]}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Parameter"}),(0,r.jsx)(n.th,{children:"Description"}),(0,r.jsx)(n.th,{children:"Example value"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"managedLedgerMinLedgerRolloverTimeMinutes"})}),(0,r.jsxs)(n.td,{children:["Minimum time between ledger rollover for a topic. ",(0,r.jsx)("br",{}),(0,r.jsx)("br",{}),(0,r.jsx)(n.strong,{children:"Note"}),": it is not recommended to set this parameter in the production environment."]}),(0,r.jsx)(n.td,{children:"10"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"managedLedgerMaxEntriesPerLedger"})}),(0,r.jsxs)(n.td,{children:["Maximum number of entries to append to a ledger before triggering a rollover.",(0,r.jsx)("br",{}),(0,r.jsx)("br",{}),(0,r.jsx)(n.strong,{children:"Note"}),": it is not recommended to set this parameter in the production environment."]}),(0,r.jsx)(n.td,{children:"50000"})]})]})]}),"\n"]}),"\n"]})})]}),"\n",(0,r.jsx)(n.h3,{id:"run-filesystem-offloader-automatically",children:"Run filesystem offloader automatically"}),"\n",(0,r.jsx)(n.p,{children:"You can configure the namespace policy to offload data automatically once a threshold is reached. The threshold is based on the size of data that a topic has stored on a Pulsar cluster. Once the topic storage reaches the threshold, an offload operation is triggered automatically."}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Threshold value"}),(0,r.jsx)(n.th,{children:"Action"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"> 0"}),(0,r.jsx)(n.td,{children:"It triggers the offloading operation if the topic storage reaches its threshold."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"= 0"}),(0,r.jsx)(n.td,{children:"It causes a broker to offload data as soon as possible."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"< 0"}),(0,r.jsx)(n.td,{children:"It disables automatic offloading operation."})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"Automatic offload runs when a new segment is added to a topic log. If you set the threshold on a namespace, but few messages are being produced to the topic, the filesystem offloader does not work until the current segment is full."}),"\n",(0,r.jsx)(n.p,{children:"You can configure the threshold using CLI tools, such as pulsar-admin."}),"\n",(0,r.jsx)(n.h4,{id:"example",children:"Example"}),"\n",(0,r.jsx)(n.p,{children:"This example sets the filesystem offloader threshold to 10 MB using pulsar-admin."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"pulsar-admin namespaces set-offload-threshold --size 10M my-tenant/my-namespace\n"})}),"\n",(0,r.jsx)(n.admonition,{type:"tip",children:(0,r.jsxs)(n.p,{children:["For more information about the ",(0,r.jsx)(n.code,{children:"pulsar-admin namespaces set-offload-threshold options"})," command, including flags, descriptions, default values, and shorthands, see ",(0,r.jsx)(n.a,{href:"pathname:///reference/#/next/pulsar-admin/",children:"Pulsar admin docs"}),"."]})}),"\n",(0,r.jsx)(n.h3,{id:"run-filesystem-offloader-manually",children:"Run filesystem offloader manually"}),"\n",(0,r.jsx)(n.p,{children:"For individual topics, you can trigger the filesystem offloader manually using one of the following methods:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Use the REST endpoint."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Use CLI tools (such as pulsar-admin)."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"To manually trigger the filesystem offloader via CLI tools, you need to specify the maximum amount of data (threshold) that should be retained on a Pulsar cluster for a topic. If the size of the topic data on the Pulsar cluster exceeds this threshold, segments from the topic are offloaded to the filesystem until the threshold is no longer exceeded. Older segments are offloaded first."}),"\n",(0,r.jsx)(n.h4,{id:"example-1",children:"Example"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"This example manually runs the filesystem offloader using pulsar-admin."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"pulsar-admin topics offload --size-threshold 10M persistent://my-tenant/my-namespace/topic1\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Output"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"Offload triggered for persistent://my-tenant/my-namespace/topic1 for messages before 2:0:-1\n"})}),"\n",(0,r.jsx)(n.admonition,{type:"tip",children:(0,r.jsxs)(n.p,{children:["For more information about the ",(0,r.jsx)(n.code,{children:"pulsar-admin topics offload options"})," command, including flags, descriptions, default values, and shorthands, see ",(0,r.jsx)(n.a,{href:"pathname:///reference/#/next/pulsar-admin/",children:"Pulsar admin docs"}),"."]})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"This example checks filesystem offloader status using pulsar-admin."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"pulsar-admin topics offload-status persistent://my-tenant/my-namespace/topic1\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Output"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"Offload is currently running\n"})}),"\n",(0,r.jsxs)(n.p,{children:["To wait for the filesystem to complete the job, add the ",(0,r.jsx)(n.code,{children:"-w"})," flag."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"pulsar-admin topics offload-status -w persistent://my-tenant/my-namespace/topic1\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Output"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Offload was a success\n"})}),"\n",(0,r.jsxs)(n.p,{children:["If there is an error in the offloading operation, the error is propagated to the ",(0,r.jsx)(n.code,{children:"pulsar-admin topics offload-status"})," command."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"pulsar-admin topics offload-status persistent://my-tenant/my-namespace/topic1\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Output"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Error in offload\nnull\n\nReason: Error offloading: org.apache.bookkeeper.mledger.ManagedLedgerException: java.util.concurrent.CompletionException: com.amazonaws.services.s3.model.AmazonS3Exception: Anonymous users cannot initiate multipart uploads.  Please authenticate. (Service: Amazon S3; Status Code: 403; Error Code: AccessDenied; Request ID: 798758DE3F1776DF; S3 Extended Request ID: dhBFz/lZm1oiG/oBEepeNlhrtsDlzoOhocuYMpKihQGXe6EG8puRGOkK6UwqzVrMXTWBxxHcS+g=), S3 Extended Request ID: dhBFz/lZm1oiG/oBEepeNlhrtsDlzoOhocuYMpKihQGXe6EG8puRGOkK6UwqzVrMXTWBxxHcS+g=\n"})}),"\n",(0,r.jsx)(n.admonition,{type:"tip",children:(0,r.jsxs)(n.p,{children:["For more information about the ",(0,r.jsx)(n.code,{children:"pulsar-admin topics offload-status options"})," command, including flags, descriptions, default values, and shorthands, see ",(0,r.jsx)(n.a,{href:"pathname:///reference/#/next/pulsar-admin/",children:"Pulsar admin docs"}),"."]})}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"tutorial",children:"Tutorial"}),"\n",(0,r.jsx)(n.p,{children:"This section provides step-by-step instructions on how to use the filesystem offloader to move data from Pulsar to Hadoop Distributed File System (HDFS) or Network File system (NFS)."}),"\n",(0,r.jsx)(n.h3,{id:"offload-data-to-hdfs",children:"Offload data to HDFS"}),"\n",(0,r.jsx)(n.admonition,{type:"tip",children:(0,r.jsxs)(n.p,{children:["This tutorial sets up a Hadoop single node cluster and uses Hadoop 3.2.1. For details about how to set up a Hadoop single node cluster, see ",(0,r.jsx)(n.a,{href:"https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html",children:"here"}),"."]})}),"\n",(0,r.jsx)(n.h4,{id:"step-1-prepare-the-hdfs-environment",children:"Step 1: Prepare the HDFS environment"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Download and uncompress Hadoop 3.2.1."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"wget https://mirrors.bfsu.edu.cn/apache/hadoop/common/hadoop-3.2.1/hadoop-3.2.1.tar.gz\n\ntar -zxvf hadoop-3.2.1.tar.gz -C $HADOOP_HOME\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Configure Hadoop."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-xml",children:"# $HADOOP_HOME/etc/hadoop/core-site.xml\n<configuration>\n    <property>\n        <name>fs.defaultFS</name>\n        <value>hdfs://localhost:9000</value>\n    </property>\n</configuration>\n\n# $HADOOP_HOME/etc/hadoop/hdfs-site.xml\n<configuration>\n    <property>\n        <name>dfs.replication</name>\n        <value>1</value>\n    </property>\n</configuration>\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Set passphraseless ssh."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Now check that you can ssh to the localhost without a passphrase:\nssh localhost\n# If you cannot ssh to localhost without a passphrase, execute the following commands\nssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa\ncat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys\nchmod 0600 ~/.ssh/authorized_keys\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Start HDFS."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# don't execute this command repeatedly, repeat execute will cauld the clusterId of the datanode is not consistent with namenode\n$HADOOP_HOME/bin/hadoop namenode -format\n$HADOOP_HOME/sbin/start-dfs.sh\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Navigate to the ",(0,r.jsx)(n.a,{href:"http://localhost:9870/",children:"HDFS website"}),"."]}),"\n",(0,r.jsxs)(n.p,{children:["You can see the ",(0,r.jsx)(n.strong,{children:"Overview"})," page."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:s(66023).A+"",width:"2396",height:"1668"})}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["At the top navigation bar, click ",(0,r.jsx)(n.strong,{children:"Datanodes"})," to check DataNode information."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:s(9871).A+"",width:"2452",height:"1638"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Click ",(0,r.jsx)(n.strong,{children:"HTTP Address"})," to get more detailed information about localhost:9866."]}),"\n",(0,r.jsxs)(n.p,{children:["As can be seen below, the size of ",(0,r.jsx)(n.strong,{children:"Capacity Used"})," is 4 KB, which is the initial value."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:s(28326).A+"",width:"2392",height:"1504"})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"step-2-install-the-filesystem-offloader",children:"Step 2: Install the filesystem offloader"}),"\n",(0,r.jsxs)(n.p,{children:["For details, see ",(0,r.jsx)(n.a,{href:"#installation",children:"installation"}),"."]}),"\n",(0,r.jsx)(n.h4,{id:"step-3-configure-the-filesystem-offloader",children:"Step 3: Configure the filesystem offloader"}),"\n",(0,r.jsxs)(n.p,{children:["As indicated in the ",(0,r.jsx)(n.a,{href:"#configuration",children:"configuration"})," section, you need to configure some properties for the filesystem offloader driver before using it. This tutorial assumes that you have configured the filesystem offloader driver as below and run Pulsar in ",(0,r.jsx)(n.strong,{children:"standalone"})," mode."]}),"\n",(0,r.jsxs)(n.p,{children:["Set the following configurations in the ",(0,r.jsx)(n.code,{children:"conf/standalone.conf"})," file."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-conf",children:"managedLedgerOffloadDriver=filesystem\nfileSystemURI=hdfs://127.0.0.1:9000\nfileSystemProfilePath=conf/filesystem_offload_core_site.xml\n"})}),"\n",(0,r.jsx)(n.admonition,{type:"note",children:(0,r.jsx)(n.p,{children:"For testing purposes, you can set the following two configurations to speed up ledger rollover, but it is not recommended that you set them in the production environment."})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-conf",children:"managedLedgerMinLedgerRolloverTimeMinutes=1\nmanagedLedgerMaxEntriesPerLedger=100\n"})}),"\n",(0,r.jsx)(n.h4,{id:"step-4-offload-data-from-bookkeeper-to-filesystem",children:"Step 4: Offload data from BookKeeper to filesystem"}),"\n",(0,r.jsxs)(n.p,{children:["Execute the following commands in the repository where you download Pulsar tarball. For example, ",(0,r.jsx)(n.code,{children:"~/path/to/apache-pulsar-2.5.1"}),"."]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Start Pulsar standalone."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"bin/pulsar standalone -a 127.0.0.1\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["To ensure the data generated is not deleted immediately, it is recommended to set the ",(0,r.jsx)(n.a,{href:"/docs/next/cookbooks-retention-expiry#retention-policies",children:"retention policy"}),", which can be either a ",(0,r.jsx)(n.strong,{children:"size"})," limit or a ",(0,r.jsx)(n.strong,{children:"time"})," limit. The larger value you set for the retention policy, the longer the data can be retained."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"bin/pulsar-admin namespaces set-retention public/default --size 100M --time 2d\n"})}),"\n",(0,r.jsx)(n.admonition,{type:"tip",children:(0,r.jsxs)(n.p,{children:["For more information about the ",(0,r.jsx)(n.code,{children:"pulsarctl namespaces set-retention options"})," command, including flags, descriptions, default values, and shorthands, see ",(0,r.jsx)(n.a,{href:"https://docs.streamnative.io/pulsarctl/v2.7.0.6/#-em-set-retention-em-",children:"here"}),"."]})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Produce data using pulsar-client."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:'bin/pulsar-client produce -m "Hello FileSystem Offloader" -n 1000 public/default/fs-test\n'})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"The offloading operation starts after a ledger rollover is triggered. To ensure offload data successfully, it is recommended that you wait until several ledger rollovers are triggered. In this case, you might need to wait for a second. You can check the ledger status using pulsarctl."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"bin/pulsar-admin topics stats-internal public/default/fs-test\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Output"})}),"\n",(0,r.jsx)(n.p,{children:"The data of the ledger 696 is not offloaded."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:'{\n"version": 1,\n"creationDate": "2020-06-16T21:46:25.807+08:00",\n"modificationDate": "2020-06-16T21:46:25.821+08:00",\n"ledgers": [\n{\n    "ledgerId": 696,\n    "isOffloaded": false\n}\n],\n"cursors": {}\n}\n'})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Wait for a second and send more messages to the topic."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:'bin/pulsar-client produce -m "Hello FileSystem Offloader" -n 1000 public/default/fs-test\n'})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Check the ledger status using pulsarctl."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"bin/pulsar-admin topics stats-internal public/default/fs-test\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Output"})}),"\n",(0,r.jsx)(n.p,{children:"The ledger 696 is rolled over."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:'{\n"version": 2,\n"creationDate": "2020-06-16T21:46:25.807+08:00",\n"modificationDate": "2020-06-16T21:48:52.288+08:00",\n"ledgers": [\n{\n    "ledgerId": 696,\n    "entries": 1001,\n    "size": 81695,\n    "isOffloaded": false\n},\n{\n    "ledgerId": 697,\n    "isOffloaded": false\n}\n],\n"cursors": {}\n}\n'})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Trigger the offloading operation manually using pulsarctl."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"bin/pulsar-admin topics offload -s 0 public/default/fs-test\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Output"})}),"\n",(0,r.jsx)(n.p,{children:"Data in ledgers before the ledger 697 is offloaded."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"# offload info, the ledgers before 697 will be offloaded\nOffload triggered for persistent://public/default/fs-test3 for messages before 697:0:-1\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Check the ledger status using pulsarctl."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"bin/pulsar-admin topics stats-internal public/default/fs-test\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Output"})}),"\n",(0,r.jsx)(n.p,{children:"The data of the ledger 696 is offloaded."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:'{\n"version": 4,\n"creationDate": "2020-06-16T21:46:25.807+08:00",\n"modificationDate": "2020-06-16T21:52:13.25+08:00",\n"ledgers": [\n{\n    "ledgerId": 696,\n    "entries": 1001,\n    "size": 81695,\n    "isOffloaded": true\n},\n{\n    "ledgerId": 697,\n    "isOffloaded": false\n}\n],\n"cursors": {}\n}\n'})}),"\n",(0,r.jsxs)(n.p,{children:["And the ",(0,r.jsx)(n.strong,{children:"Capacity Used"})," is changed from 4 KB to 116.46 KB."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:s(69189).A+"",width:"2422",height:"1498"})}),"\n",(0,r.jsx)(n.h3,{id:"offload-data-to-nfs",children:"Offload data to NFS"}),"\n",(0,r.jsx)(n.admonition,{type:"note",children:(0,r.jsxs)(n.p,{children:["In this section, it is assumed that you have enabled NFS service and set the shared path of your NFS service. In this section, ",(0,r.jsx)(n.code,{children:"/Users/test"})," is used as the shared path of NFS service."]})}),"\n",(0,r.jsx)(n.h4,{id:"step-1-install-the-filesystem-offloader",children:"Step 1: Install the filesystem offloader"}),"\n",(0,r.jsxs)(n.p,{children:["For details, see ",(0,r.jsx)(n.a,{href:"#installation",children:"installation"}),"."]}),"\n",(0,r.jsx)(n.h4,{id:"step-2-mount-your-nfs-to-your-local-filesystem",children:"Step 2: Mount your NFS to your local filesystem"}),"\n",(0,r.jsxs)(n.p,{children:["This example mounts ",(0,r.jsx)(n.em,{children:"/Users/pulsar_nfs"})," to ",(0,r.jsx)(n.em,{children:"/Users/test"}),"."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"mount -e 192.168.0.103:/Users/test/Users/pulsar_nfs\n"})}),"\n",(0,r.jsx)(n.h4,{id:"step-3-configure-the-filesystem-offloader-driver",children:"Step 3: Configure the filesystem offloader driver"}),"\n",(0,r.jsxs)(n.p,{children:["As indicated in the ",(0,r.jsx)(n.a,{href:"#configuration",children:"configuration"})," section, you need to configure some properties for the filesystem offloader driver before using it. This tutorial assumes that you have configured the filesystem offloader driver as below and run Pulsar in ",(0,r.jsx)(n.strong,{children:"standalone"})," mode."]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Set the following configurations in the ",(0,r.jsx)(n.code,{children:"conf/standalone.conf"})," file."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-conf",children:"managedLedgerOffloadDriver=filesystem\nfileSystemProfilePath=conf/filesystem_offload_core_site.xml\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Modify the ",(0,r.jsx)(n.em,{children:"filesystem_offload_core_site.xml"})," as follows."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-xml",children:"<property>\n    <name>fs.defaultFS</name>\n    <value>file:///</value>\n</property>\n\n<property>\n    <name>hadoop.tmp.dir</name>\n    <value>file:///Users/pulsar_nfs</value>\n</property>\n\n<property>\n    <name>io.file.buffer.size</name>\n    <value>4096</value>\n</property>\n\n<property>\n    <name>io.seqfile.compress.blocksize</name>\n    <value>1000000</value>\n</property>\n<property>\n\n    <name>io.seqfile.compression.type</name>\n    <value>BLOCK</value>\n</property>\n\n<property>\n    <name>io.map.index.interval</name>\n    <value>128</value>\n</property>\n"})}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"step-4-offload-data-from-bookkeeper-to-filesystem-1",children:"Step 4: Offload data from BookKeeper to filesystem"}),"\n",(0,r.jsxs)(n.p,{children:["Refer to the step 4 of ",(0,r.jsx)(n.a,{href:"#step-4-offload-data-from-bookkeeper-to-filesystem",children:"Offload data to HDFS"}),"."]}),"\n",(0,r.jsx)(n.h2,{id:"read-offloaded-data-from-filesystem",children:"Read offloaded data from filesystem"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["The offloaded data is stored as ",(0,r.jsx)(n.code,{children:"MapFile"})," in the following new path of the filesystem:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-properties",children:'path = storageBasePath + "/" + managedLedgerName + "/" + ledgerId + "-" + uuid.toString();\n'})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"storageBasePath"})," is the value of ",(0,r.jsx)(n.code,{children:"hadoop.tmp.dir"}),", which is configured in ",(0,r.jsx)(n.code,{children:"broker.conf"})," or ",(0,r.jsx)(n.code,{children:"filesystem_offload_core_site.xml"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"managedLedgerName"})," is the ledger name of the persistentTopic manager."]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"managedLedgerName of persistent://public/default/topics-name is public/default/persistent/topics-name.\n"})}),"\n",(0,r.jsxs)(n.p,{children:["You can use the following method to get ",(0,r.jsx)(n.code,{children:"managedLedgerName"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:'String managedLedgerName = TopicName.get("persistent://public/default/topics-name").getPersistenceNamingEncoding();\n'})}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"To read data out as ledger entries from the filesystem, complete the following steps."}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["Create a reader to read both ",(0,r.jsx)(n.code,{children:"MapFile"})," with a new path and the ",(0,r.jsx)(n.code,{children:"configuration"})," of the filesystem."]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"MapFile.Reader reader = new MapFile.Reader(new Path(dataFilePath),  configuration);\n"})}),"\n",(0,r.jsxs)(n.ol,{start:"2",children:["\n",(0,r.jsxs)(n.li,{children:["Read the data as ",(0,r.jsx)(n.code,{children:"LedgerEntry"})," from the filesystem."]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:"  LongWritable key = new LongWritable();\n  BytesWritable value = new BytesWritable();\n  key.set(nextExpectedId - 1);\n  reader.seek(key);\n  reader.next(key, value);\n  int length = value.getLength();\n  long entryId = key.get();\n  ByteBuf buf = PooledByteBufAllocator.DEFAULT.buffer(length, length);\n  buf.writeBytes(value.copyBytes());\n  LedgerEntryImpl ledgerEntry = LedgerEntryImpl.create(ledgerId, entryId, length, buf);\n"})}),"\n",(0,r.jsxs)(n.ol,{start:"3",children:["\n",(0,r.jsxs)(n.li,{children:["Deserialize the ",(0,r.jsx)(n.code,{children:"LedgerEntry"})," to ",(0,r.jsx)(n.code,{children:"Message"}),"."]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:'     ByteBuf metadataAndPayload = ledgerEntry.getDataBuffer();\n     long totalSize = metadataAndPayload.readableBytes();\n     BrokerEntryMetadata brokerEntryMetadata = Commands.peekBrokerEntryMetadataIfExist(metadataAndPayload);\n     MessageMetadata metadata = Commands.parseMessageMetadata(metadataAndPayload);\n\n     Map<String, String> properties = new TreeMap();\n     properties.put("X-Pulsar-batch-size", String.valueOf(totalSize\n             - metadata.getSerializedSize()));\n     properties.put("TOTAL-CHUNKS", Integer.toString(metadata.getNumChunksFromMsg()));\n     properties.put("CHUNK-ID", Integer.toString(metadata.getChunkId()));\n\n     // Decode if needed\n     CompressionCodec codec = CompressionCodecProvider.getCompressionCodec(metadata.getCompression());\n     ByteBuf uncompressedPayload = codec.decode(metadataAndPayload, metadata.getUncompressedSize());\n     // Copy into a heap buffer for output stream compatibility\n     ByteBuf data = PulsarByteBufAllocator.DEFAULT.heapBuffer(uncompressedPayload.readableBytes(),\n             uncompressedPayload.readableBytes());\n     data.writeBytes(uncompressedPayload);\n     uncompressedPayload.release();\n\n     MessageImpl message = new MessageImpl(topic, ((PositionImpl)ledgerEntry.getPosition()).toString(), properties,\n             data, Schema.BYTES, metadata);\n     message.setBrokerEntryMetadata(brokerEntryMetadata);\n'})})]})}function u(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(f,{...e})}):f(e)}},19365:(e,n,s)=>{s.d(n,{A:()=>l});s(96540);var t=s(34164);const r={tabItem:"tabItem_Ymn6"};var a=s(74848);function l(e){let{children:n,hidden:s,className:l}=e;return(0,a.jsx)("div",{role:"tabpanel",className:(0,t.A)(r.tabItem,l),hidden:s,children:n})}},11470:(e,n,s)=>{s.d(n,{A:()=>S});var t=s(96540),r=s(34164),a=s(23104),l=s(56347),i=s(205),o=s(57485),d=s(31682),c=s(70679);function h(e){return t.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,t.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function f(e){const{values:n,children:s}=e;return(0,t.useMemo)((()=>{const e=n??function(e){return h(e).map((e=>{let{props:{value:n,label:s,attributes:t,default:r}}=e;return{value:n,label:s,attributes:t,default:r}}))}(s);return function(e){const n=(0,d.XI)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,s])}function u(e){let{value:n,tabValues:s}=e;return s.some((e=>e.value===n))}function p(e){let{queryString:n=!1,groupId:s}=e;const r=(0,l.W6)(),a=function(e){let{queryString:n=!1,groupId:s}=e;if("string"==typeof n)return n;if(!1===n)return null;if(!0===n&&!s)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return s??null}({queryString:n,groupId:s});return[(0,o.aZ)(a),(0,t.useCallback)((e=>{if(!a)return;const n=new URLSearchParams(r.location.search);n.set(a,e),r.replace({...r.location,search:n.toString()})}),[a,r])]}function m(e){const{defaultValue:n,queryString:s=!1,groupId:r}=e,a=f(e),[l,o]=(0,t.useState)((()=>function(e){let{defaultValue:n,tabValues:s}=e;if(0===s.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(n){if(!u({value:n,tabValues:s}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${n}" but none of its children has the corresponding value. Available values are: ${s.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return n}const t=s.find((e=>e.default))??s[0];if(!t)throw new Error("Unexpected error: 0 tabValues");return t.value}({defaultValue:n,tabValues:a}))),[d,h]=p({queryString:s,groupId:r}),[m,x]=function(e){let{groupId:n}=e;const s=function(e){return e?`docusaurus.tab.${e}`:null}(n),[r,a]=(0,c.Dv)(s);return[r,(0,t.useCallback)((e=>{s&&a.set(e)}),[s,a])]}({groupId:r}),g=(()=>{const e=d??m;return u({value:e,tabValues:a})?e:null})();(0,i.A)((()=>{g&&o(g)}),[g]);return{selectedValue:l,selectValue:(0,t.useCallback)((e=>{if(!u({value:e,tabValues:a}))throw new Error(`Can't select invalid tab value=${e}`);o(e),h(e),x(e)}),[h,x,a]),tabValues:a}}var x=s(92303);const g={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var j=s(74848);function y(e){let{className:n,block:s,selectedValue:t,selectValue:l,tabValues:i}=e;const o=[],{blockElementScrollPositionUntilNextRender:d}=(0,a.a_)(),c=e=>{const n=e.currentTarget,s=o.indexOf(n),r=i[s].value;r!==t&&(d(n),l(r))},h=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const s=o.indexOf(e.currentTarget)+1;n=o[s]??o[0];break}case"ArrowLeft":{const s=o.indexOf(e.currentTarget)-1;n=o[s]??o[o.length-1];break}}n?.focus()};return(0,j.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.A)("tabs",{"tabs--block":s},n),children:i.map((e=>{let{value:n,label:s,attributes:a}=e;return(0,j.jsx)("li",{role:"tab",tabIndex:t===n?0:-1,"aria-selected":t===n,ref:e=>o.push(e),onKeyDown:h,onClick:c,...a,className:(0,r.A)("tabs__item",g.tabItem,a?.className,{"tabs__item--active":t===n}),children:s??n},n)}))})}function b(e){let{lazy:n,children:s,selectedValue:a}=e;const l=(Array.isArray(s)?s:[s]).filter(Boolean);if(n){const e=l.find((e=>e.props.value===a));return e?(0,t.cloneElement)(e,{className:(0,r.A)("margin-top--md",e.props.className)}):null}return(0,j.jsx)("div",{className:"margin-top--md",children:l.map(((e,n)=>(0,t.cloneElement)(e,{key:n,hidden:e.props.value!==a})))})}function v(e){const n=m(e);return(0,j.jsxs)("div",{className:(0,r.A)("tabs-container",g.tabList),children:[(0,j.jsx)(y,{...n,...e}),(0,j.jsx)(b,{...n,...e})]})}function S(e){const n=(0,x.A)();return(0,j.jsx)(v,{...e,children:h(e.children)},String(n))}},66023:(e,n,s)=>{s.d(n,{A:()=>t});const t=s.p+"assets/images/FileSystem-1-8fba41a03bedc3e2d89a0fccf0b80f0f.png"},9871:(e,n,s)=>{s.d(n,{A:()=>t});const t=s.p+"assets/images/FileSystem-2-e35ac7fd0ad15579667dde0f831eaa02.png"},28326:(e,n,s)=>{s.d(n,{A:()=>t});const t=s.p+"assets/images/FileSystem-3-0c94a33a238a8753b06d8e9e99fc31fc.png"},69189:(e,n,s)=>{s.d(n,{A:()=>t});const t=s.p+"assets/images/FileSystem-8-679ffa9ebb34e9242170e98af24d67d6.png"},28453:(e,n,s)=>{s.d(n,{R:()=>l,x:()=>i});var t=s(96540);const r={},a=t.createContext(r);function l(e){const n=t.useContext(a);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:l(e.components),t.createElement(a.Provider,{value:n},e.children)}}}]);