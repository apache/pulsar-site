"use strict";(self.webpackChunkwebsite_next=self.webpackChunkwebsite_next||[]).push([[2878],{14587:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>c,default:()=>h,frontMatter:()=>t,metadata:()=>a,toc:()=>l});const a=JSON.parse('{"id":"io-kafka-source","title":"Kafka source connector","description":"The Kafka source connector pulls messages from Kafka topics and persists the messages","source":"@site/versioned_docs/version-2.8.x/io-kafka-source.md","sourceDirName":".","slug":"/io-kafka-source","permalink":"/docs/2.8.x/io-kafka-source","draft":false,"unlisted":false,"editUrl":"https://github.com/apache/pulsar-site/edit/main/versioned_docs/version-2.8.x/io-kafka-source.md","tags":[],"version":"2.8.x","frontMatter":{"id":"io-kafka-source","title":"Kafka source connector","sidebar_label":"Kafka source connector","original_id":"io-kafka-source"}}');var r=s(74848),i=s(28453);const t={id:"io-kafka-source",title:"Kafka source connector",sidebar_label:"Kafka source connector",original_id:"io-kafka-source"},c=void 0,o={},l=[{value:"Configuration",id:"configuration",level:2},{value:"Property",id:"property",level:3},{value:"Schema Management",id:"schema-management",level:3},{value:"Example",id:"example",level:3},{value:"Usage",id:"usage",level:2}];function d(e){const n={a:"a",code:"code",em:"em",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.p,{children:"The Kafka source connector pulls messages from Kafka topics and persists the messages\nto Pulsar topics."}),"\n",(0,r.jsx)(n.p,{children:"This guide explains how to configure and use the Kafka source connector."}),"\n",(0,r.jsx)(n.h2,{id:"configuration",children:"Configuration"}),"\n",(0,r.jsx)(n.p,{children:"The configuration of the Kafka source connector has the following properties."}),"\n",(0,r.jsx)(n.h3,{id:"property",children:"Property"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Name"}),(0,r.jsx)(n.th,{children:"Type"}),(0,r.jsx)(n.th,{children:"Required"}),(0,r.jsx)(n.th,{children:"Default"}),(0,r.jsx)(n.th,{children:"Description"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"bootstrapServers"})}),(0,r.jsx)(n.td,{children:"String"}),(0,r.jsx)(n.td,{children:"true"}),(0,r.jsx)(n.td,{children:'" " (empty string)'}),(0,r.jsx)(n.td,{children:"A comma-separated list of host and port pairs for establishing the initial connection to the Kafka cluster."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"groupId"})}),(0,r.jsx)(n.td,{children:"String"}),(0,r.jsx)(n.td,{children:"true"}),(0,r.jsx)(n.td,{children:'" " (empty string)'}),(0,r.jsx)(n.td,{children:"A unique string that identifies the group of consumer processes to which this consumer belongs."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"fetchMinBytes"})}),(0,r.jsx)(n.td,{children:"long"}),(0,r.jsx)(n.td,{children:"false"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"The minimum byte expected for each fetch response."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"autoCommitEnabled"})}),(0,r.jsx)(n.td,{children:"boolean"}),(0,r.jsx)(n.td,{children:"false"}),(0,r.jsx)(n.td,{children:"true"}),(0,r.jsxs)(n.td,{children:["If set to true, the consumer's offset is periodically committed in the background.",(0,r.jsx)("br",{}),(0,r.jsx)("br",{})," This committed offset is used when the process fails as the position from which a new consumer begins."]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"autoCommitIntervalMs"})}),(0,r.jsx)(n.td,{children:"long"}),(0,r.jsx)(n.td,{children:"false"}),(0,r.jsx)(n.td,{children:"5000"}),(0,r.jsxs)(n.td,{children:["The frequency in milliseconds that the consumer offsets are auto-committed to Kafka if ",(0,r.jsx)(n.code,{children:"autoCommitEnabled"})," is set to true."]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"heartbeatIntervalMs"})}),(0,r.jsx)(n.td,{children:"long"}),(0,r.jsx)(n.td,{children:"false"}),(0,r.jsx)(n.td,{children:"3000"}),(0,r.jsxs)(n.td,{children:["The interval between heartbeats to the consumer when using Kafka's group management facilities. ",(0,r.jsx)("br",{}),(0,r.jsx)("br",{}),(0,r.jsxs)(n.strong,{children:["Note: ",(0,r.jsx)(n.code,{children:"heartbeatIntervalMs"})," must be smaller than ",(0,r.jsx)(n.code,{children:"sessionTimeoutMs"})]}),"."]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"sessionTimeoutMs"})}),(0,r.jsx)(n.td,{children:"long"}),(0,r.jsx)(n.td,{children:"false"}),(0,r.jsx)(n.td,{children:"30000"}),(0,r.jsx)(n.td,{children:"The timeout used to detect consumer failures when using Kafka's group management facility."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"topic"})}),(0,r.jsx)(n.td,{children:"String"}),(0,r.jsx)(n.td,{children:"true"}),(0,r.jsx)(n.td,{children:'" " (empty string)'}),(0,r.jsx)(n.td,{children:"The Kafka topic which sends messages to Pulsar."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"consumerConfigProperties"})}),(0,r.jsx)(n.td,{children:"Map"}),(0,r.jsx)(n.td,{children:"false"}),(0,r.jsx)(n.td,{children:'" " (empty string)'}),(0,r.jsxs)(n.td,{children:["The consumer configuration properties to be passed to consumers. ",(0,r.jsx)("br",{}),(0,r.jsx)("br",{}),(0,r.jsx)(n.strong,{children:"Note: other properties specified in the connector configuration file take precedence over this configuration"}),"."]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"keyDeserializationClass"})}),(0,r.jsx)(n.td,{children:"String"}),(0,r.jsx)(n.td,{children:"false"}),(0,r.jsx)(n.td,{children:"org.apache.kafka.common.serialization.StringDeserializer"}),(0,r.jsxs)(n.td,{children:["The deserializer class for Kafka consumers to deserialize keys.",(0,r.jsx)("br",{})," The deserializer is set by a specific implementation of ",(0,r.jsx)(n.a,{href:"https://github.com/apache/pulsar/blob/master/pulsar-io/kafka/src/main/java/org/apache/pulsar/io/kafka/KafkaAbstractSource.java",children:(0,r.jsx)(n.code,{children:"KafkaAbstractSource"})}),"."]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"valueDeserializationClass"})}),(0,r.jsx)(n.td,{children:"String"}),(0,r.jsx)(n.td,{children:"false"}),(0,r.jsx)(n.td,{children:"org.apache.kafka.common.serialization.ByteArrayDeserializer"}),(0,r.jsx)(n.td,{children:"The deserializer class for Kafka consumers to deserialize values."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"autoOffsetReset"})}),(0,r.jsx)(n.td,{children:"String"}),(0,r.jsx)(n.td,{children:"false"}),(0,r.jsx)(n.td,{children:'"earliest"'}),(0,r.jsx)(n.td,{children:"The default offset reset policy."})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"schema-management",children:"Schema Management"}),"\n",(0,r.jsxs)(n.p,{children:["This Kafka source connector applies the schema to the topic depending on the data type that is present on the Kafka topic.\nYou can detect the data type from the ",(0,r.jsx)(n.code,{children:"keyDeserializationClass"})," and ",(0,r.jsx)(n.code,{children:"valueDeserializationClass"})," configuration parameters."]}),"\n",(0,r.jsxs)(n.p,{children:["If the ",(0,r.jsx)(n.code,{children:"valueDeserializationClass"})," is ",(0,r.jsx)(n.code,{children:"org.apache.kafka.common.serialization.StringDeserializer"}),", you can set Schema.STRING() as schema type on the Pulsar topic."]}),"\n",(0,r.jsxs)(n.p,{children:["If ",(0,r.jsx)(n.code,{children:"valueDeserializationClass"})," is ",(0,r.jsx)(n.code,{children:"io.confluent.kafka.serializers.KafkaAvroDeserializer"}),", Pulsar downloads the AVRO schema from the Confluent Schema Registry\xae\nand sets it properly on the Pulsar topic."]}),"\n",(0,r.jsxs)(n.p,{children:["In this case, you need to set ",(0,r.jsx)(n.code,{children:"schema.registry.url"})," inside of the ",(0,r.jsx)(n.code,{children:"consumerConfigProperties"})," configuration entry\nof the source."]}),"\n",(0,r.jsxs)(n.p,{children:["If ",(0,r.jsx)(n.code,{children:"keyDeserializationClass"})," is not ",(0,r.jsx)(n.code,{children:"org.apache.kafka.common.serialization.StringDeserializer"}),", it means\nthat you do not have a String as key and the Kafka Source uses the KeyValue schema type with the SEPARATED encoding."]}),"\n",(0,r.jsx)(n.p,{children:"Pulsar supports AVRO format for keys."}),"\n",(0,r.jsx)(n.p,{children:"In this case, you can have a Pulsar topic with the following properties:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Schema: KeyValue schema with SEPARATED encoding"}),"\n",(0,r.jsx)(n.li,{children:"Key: the content of key of the Kafka message (base64 encoded)"}),"\n",(0,r.jsx)(n.li,{children:"Value: the content of value of the Kafka message"}),"\n",(0,r.jsxs)(n.li,{children:["KeySchema: the schema detected from ",(0,r.jsx)(n.code,{children:"keyDeserializationClass"})]}),"\n",(0,r.jsxs)(n.li,{children:["ValueSchema: the schema detected from ",(0,r.jsx)(n.code,{children:"valueDeserializationClass"})]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Topic compaction and partition routing use the Pulsar key, that contains the Kafka key, and so they are driven by the same value that you have on Kafka."}),"\n",(0,r.jsxs)(n.p,{children:["When you consume data from Pulsar topics, you can use the ",(0,r.jsx)(n.code,{children:"KeyValue"})," schema. In this way, you can decode the data properly.\nIf you want to access the raw key, you can use the ",(0,r.jsx)(n.code,{children:"Message#getKeyBytes()"})," API."]}),"\n",(0,r.jsx)(n.h3,{id:"example",children:"Example"}),"\n",(0,r.jsx)(n.p,{children:"Before using the Kafka source connector, you need to create a configuration file through one of the following methods."}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"JSON"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-json",children:'\n{\n    "bootstrapServers": "pulsar-kafka:9092",\n    "groupId": "test-pulsar-io",\n    "topic": "my-topic",\n    "sessionTimeoutMs": "10000",\n    "autoCommitEnabled": false\n}\n\n'})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"YAML"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:'\nconfigs:\n    bootstrapServers: "pulsar-kafka:9092"\n    groupId: "test-pulsar-io"\n    topic: "my-topic"\n    sessionTimeoutMs: "10000"\n    autoCommitEnabled: false\n\n'})}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"usage",children:"Usage"}),"\n",(0,r.jsx)(n.p,{children:"Here is an example of using the Kafka source connector with the configuration file as shown previously."}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Download a Kafka client and a Kafka connector."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"\n$ wget https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/0.10.2.1/kafka-clients-0.10.2.1.jar\n\n$ wget https://archive.apache.org/dist/pulsar/pulsar-2.4.0/connectors/pulsar-io-kafka-2.4.0.nar\n\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Create a network."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"\n$ docker network create kafka-pulsar\n\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Pull a ZooKeeper image and start ZooKeeper."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"\n$ docker pull wurstmeister/zookeeper\n\n$ docker run -d -it -p 2181:2181 --name pulsar-kafka-zookeeper --network kafka-pulsar wurstmeister/zookeeper\n\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Pull a Kafka image and start Kafka."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"\n$ docker pull wurstmeister/kafka:2.11-1.0.2\n\n$ docker run -d -it --network kafka-pulsar -p 6667:6667 -p 9092:9092 -e KAFKA_ADVERTISED_HOST_NAME=pulsar-kafka -e KAFKA_ZOOKEEPER_CONNECT=pulsar-kafka-zookeeper:2181 --name pulsar-kafka wurstmeister/kafka:2.11-1.0.2\n\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Pull a Pulsar image and start Pulsar standalone."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"\n$ docker pull apachepulsar/pulsar:2.8.4\n\n$ docker run -d -it --network kafka-pulsar -p 6650:6650 -p 8080:8080 -v $PWD/data:/pulsar/data --name pulsar-kafka-standalone apachepulsar/pulsar:2.4.0 bin/pulsar standalone\n\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Create a producer file ",(0,r.jsx)(n.em,{children:"kafka-producer.py"}),"."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"\nfrom kafka import KafkaProducer\nproducer = KafkaProducer(bootstrap_servers='pulsar-kafka:9092')\nfuture = producer.send('my-topic', b'hello world')\nfuture.get()\n\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Create a consumer file ",(0,r.jsx)(n.em,{children:"pulsar-client.py"}),"."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"\nimport pulsar\n\nclient = pulsar.Client('pulsar://localhost:6650')\nconsumer = client.subscribe('my-topic', subscription_name='my-aa')\n\nwhile True:\n    msg = consumer.receive()\n    print msg\n    print dir(msg)\n    print(\"Received message: '%s'\" % msg.data())\n    consumer.acknowledge(msg)\n\nclient.close()\n\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Copy the following files to Pulsar."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"\n$ docker cp pulsar-io-kafka-2.8.4.nar pulsar-kafka-standalone:/pulsar\n$ docker cp kafkaSourceConfig.yaml pulsar-kafka-standalone:/pulsar/conf\n$ docker cp pulsar-client.py pulsar-kafka-standalone:/pulsar/\n$ docker cp kafka-producer.py pulsar-kafka-standalone:/pulsar/\n\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Open a new terminal window and start the Kafka source connector in local run mode."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"\n$ docker exec -it pulsar-kafka-standalone /bin/bash\n\n$ ./bin/pulsar-admin source localrun \\\n--archive ./pulsar-io-kafka-2.8.4.nar \\\n--classname org.apache.pulsar.io.kafka.KafkaBytesSource \\\n--tenant public \\\n--namespace default \\\n--name kafka \\\n--destination-topic-name my-topic \\\n--source-config-file ./conf/kafkaSourceConfig.yaml \\\n--parallelism 1\n\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Open a new terminal window and run the consumer."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"\n$ docker exec -it pulsar-kafka-standalone /bin/bash\n\n$ pip install kafka-python\n\n$ python3 kafka-producer.py\n\n"})}),"\n",(0,r.jsx)(n.p,{children:"The following information appears on the consumer terminal window."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"\nReceived message: 'hello world'\n\n"})})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},28453:(e,n,s)=>{s.d(n,{R:()=>t,x:()=>c});var a=s(96540);const r={},i=a.createContext(r);function t(e){const n=a.useContext(i);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:t(e.components),a.createElement(i.Provider,{value:n},e.children)}}}]);